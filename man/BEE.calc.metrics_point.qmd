---
title: "BEE.calc.metrics_point"
author: "Vico"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---

BEE.calc.metrics_point is not designed to work on 4D data (time + spatial 3D).

```{r}
# start_date <- "2022-01-01" ; end_date <- "2023-12-31" ; Values <- ds ; GPS <- data.frame(x = c(3.7659, 5.386, 3.146), y = c(43.4287, 43.183, 42.781))
BEE.calc.metrics_point <- function(Events_corrected, Values, GPS, 
                                   start_date=NULL, end_date=NULL, 
                                   baseline_qt90, baseline_mean, 
                                   group_by_event=TRUE){
  ########################################## WARNINGS ############################################################
  if ( is.null(start_date) | is.null(end_date)) {
    warning("You didn't specify a begining date and a ending date (see argument 'start_date' and 'end_date'), the first date and last date in your time Values SpatRaster will be used.")
    start_date <- min(as.Date.character(names(Values)))
    end_date <- max(as.Date.character(names(period_of_interest)))
  }
  if(class(start_date) != class(names(Values[[1]]))  | 
     class(end_date)   != class(names(Values[[1]]))  | 
     class(start_date) != class(end_date)){
    warning("The date formats are inconsistent between start_date, end_date and Values. Please ensure that the layer names follow a consistent date format. Use class(YourObject) to verify the current format.")
  }
  #Check that start date and end_date are within the SpatRasters provided
  if (!(start_date %in% names(Values)) | !(end_date %in% names(Values))) {
    warning("One or both the specified layers are not present in the SpatRaster containning corrected binarized extreme event.")
  }
  Values_extent <- terra::ext(Values)
  #Check that all GPS points are within Values and period_of_interest extent
  if ( !all(abs(GPS[1]) <= abs(Values_extent$xmax) & 
            abs(GPS[1]) >= abs(Values_extent$xmin)) ){
   warning("At least one longitude coordinate falls outside the extent of the SpatRaster containing the binarized corrected events. Ensure the first column of the dataframe contains valid longitude (x) values for analysis.")
  }
  if (!all(abs(GPS[2]) <= abs(Values_extent$ymax) & 
           abs(GPS[2]) >= abs(Values_extent$ymin))){
   warning("At least one latitude coordinate falls outside the extent of the SpatRaster containing the binarized corrected events. Ensure the second column of the dataframe contains valid latitude (y) values for analysis.")
  }
  # Check that one of the GPS position is not in a pixel that is always an NA (it may indicates that it falls in an area that is not interesting for the study)
  NA_pixels <- which(sapply(Events_corrected, function(df) all(is.na(df$Original_value)))) # List of pixel that are always NA 
  GPS$pixel <- terra::cellFromXY(Values, GPS) # List of the pixels corresponding to the GPS position provided
  if (any(GPS$pixel %in% NA_pixels)){
    wrong_position <- which(GPS$pixel %in% NA_pixels)
    message("Problematic GPS positions:\n")
    message(capture.output(print(GPS[wrong_position, ])))
    }


   ########################################## CODE ############################################################
    #Extract values for the given GPS position
  df_list  <- lapply(GPS$pixel, function(p) Events_corrected[[p]])
  Values <- t(terra::extract(Values,GPS[,3]))
    
    # Subset both dataset so they match the timeframe provided with 'start_date' and 'end_date'.
  Date <- rownames(Values)
  Values <- Values[which(as.Date(rownames(Values)) >= as.Date(start_date) & as.Date(rownames(Values)) <= as.Date(end_date)),]
  df_list <- Map(function(df, col_idx){
    df$Date <- Date
    return(df)
  }, df_list, seq_along(df_list))
  df_list <- purr::map(df_list, ~ .x[.x$Date >= start_date & .x$Date <= end_date, ])
  # For each event I want : duration, maximum intensity, mean and median intensity, category, sum of anomalies, date of maximum intensity, position of the day of maximum intensity, mean increasing slop, mean decreasing slope, start_date, end_date
  ##Contrary to Events_corrected, Values didn't kept this information of which extreme event were merge together because they were separated by d days or less. Thus, we need to use Events corrected if we want to calculate a metric that describe an event.
  
  #Merge df_list and Values
  df_list <- Map(function(df, col_idx) {
    # Ad to each dataframe the corresponding column of pixel value
    df$value <- Values[,col_idx]  # col_idx is he idee  
    return(df)
  }, df_list, seq_along(df_list))
  
  #Create a list of dataframe to store the information using one element (df) per pixel and one row per event
  colnames(GPS)<-c("x","y", names(GPS[3]))
  
  #Get daily anomaly to baseline_qt90 and to baseline_mean
  qt90 <- as.data.frame(t(terra::extract(baseline_qt90, GPS[,3])))
  qt90$dates <-format(seq(as.Date("2024-01-01"), as.Date("2024-12-31"), by = "day"), "%m-%d")
  mean <- as.data.frame(t(terra::extract(baseline_mean, GPS[,3])))
  mean$dates <- format(seq(as.Date("2024-01-01"), as.Date("2024-12-31"), by = "day"), "%m-%d")

  metrics <- lapply(1:length(df_list), function(p) { # Go through each pixel
    df <- df_list[[p]]
    df$Date <- as.Date(df$Date)
    df$dates <- format(as.Date(df$Date), "%m-%d")
    df <- df %>%
      group_by(ID) %>%
      mutate(
        # Get GPS position of each point
        x = GPS$x[p],  
        y = GPS$y[p],  
    
        # Get the ID of each event
        event_ID = unique(ID),  
    
        # Duration of each event (assuming Nb_days is constant per ID)
        Nb_days = first(Nb_days),  
    
        # First and last day of each event
        first_date = as.Date(min(Date)),
        last_date = as.Date(max(Date)),
    
        # Mean, median, max temperature per event
        mean_value = mean(value),
        median_value = median(value),
        max_value = max(value),
    
        # Day of maximum temperature
        date_max_value = as.Date(Date[which.max(value)]),
        
        #Daily rates
        daily_rates = (lead(value) - value) / as.numeric(lead(Date) - Date),
    
        # Onset rate
        days_onset = as.numeric(date_max_value - first_date),
        ## raw
        raw_onset_rate = (max_value - value[which(Date==first_date)]) / days_onset,
        ## mean
        mean_onset_rate = mean(daily_rates[Date >= first_date & Date <= date_max_value], na.rm = TRUE),
        ## Median onset rate 
        median_onset_rate = median(daily_rates[Date >= first_date & Date <= date_max_value], na.rm = TRUE),
        ## Standard deviation
        sd_onset_rate = sd(daily_rates[Date >= first_date & Date <= date_max_value], na.rm = TRUE),
    
        # Offset rate
        days_offset = as.numeric(last_date - date_max_value),
        ## raw
        raw_offset_rate = (value[which(Date==last_date)] - max_value) / days_offset,
        ## mean
        mean_offset_rate = mean(daily_rates[Date >= date_max_value & Date <= last_date], na.rm = TRUE),
        median_offset_rate = median(daily_rates[Date >= date_max_value & Date <= last_date], na.rm = TRUE),
        ## Standard deviation
        sd_offset_rate = sd(daily_rates[Date >= date_max_value & Date <= last_date], na.rm = TRUE)
      ) %>%
      ungroup()  
    # Add daily baseline_qt90 and daily baseline_mean
    df <- df %>%
      left_join(qt90[, c("dates", paste0("V", as.character(p)))], by = "dates") %>%
      rename(baseline_qt90 = paste0("V", as.character(p))) %>%
      left_join(mean[, c("dates", paste0("V", as.character(p)))], by = "dates") %>%
      rename(baseline_mean = paste0("V", as.character(p)))
    # Calculate anomalies
    df <- df %>%
    mutate(
      anomaly_qt90 = value - baseline_qt90,
      anomaly_mean = value - baseline_mean,
      anomaly_unit = baseline_qt90 - baseline_mean,
      category = case_when(
        anomaly_qt90 < anomaly_unit ~ "Category I",
        anomaly_qt90 < 2 * anomaly_unit ~ "Category II",
        anomaly_qt90 < 3 * anomaly_unit ~ "Category III",
        anomaly_qt90 >= 3 * anomaly_unit ~ "Category IV",
        TRUE ~ NA_character_
      )
    )
    # Keep the maximum category reached by each event
    category_order <- c("Category I", "Category II", "Category III", "Category IV")
    df <- df %>%
    mutate(category = factor(category, levels = category_order))
    summary_stats <- df %>%
    group_by(ID) %>%
    summarise(
      max_category = levels(category)[which.max(as.numeric(category))],  # Catégorie avec la plus grande valeur
      .groups = 'drop'
    )

    # Add mean value and standard deviation of anomaly_qt90 and anomaly_mean to the ouputs + add maximal category of each event
    summary_stats <- df %>%
    group_by(ID) %>%
    summarise(
      mean_anomaly_qt90 = mean(anomaly_qt90, na.rm = TRUE),
      sd_anomaly_qt90 = sd(anomaly_qt90, na.rm = TRUE),
      max_anomaly_qt90 = max(anomaly_qt90, na.rm = TRUE),
      mean_anomaly_mean= mean(anomaly_mean, na.rm = TRUE),
      sd_anomaly_mean = sd(anomaly_mean, na.rm = TRUE),
      max_anomaly_mean = max(anomaly_mean, na.rm = TRUE),
      max_category = names(sort(table(category), decreasing = TRUE))[1],  # Catégorie la plus fréquente
      .groups = 'drop'
    )
    df <- df %>%
    left_join(summary_stats, by = "ID")
    
    
    if (group_by_event) {
    df <- df %>%
      # Delete daily values that are not usefull to describe the full event
      select(-baseline_qt90, -baseline_mean, -anomaly_mean, -anomaly_qt90, -anomaly_unit, -category) %>%
      distinct(ID, .keep_all = TRUE)  # Une seule ligne par ID
  } else {
    df <- df 
  }
    return(df)
  })
    
  # OTHER PART TO DEVELOP : 
  # For each pixels : 
  # - anomalie cumulée par événements
  # - catégories
  # - onset rate, offset_rate (dans l'événement et depuis une période donnée avant et après dont la durée est fixée par l'utilisateur)
  #For the all period I want : Frequency, maximum intensity, mean and median intensity, sum of anomalies, date of maximum intensity, first date 1, last date 1
}
```

The categorie of each event are determined according according Hobday et al. 2018 definition

Category I : btw the 90th percentile and twice the value of the anomalies between mean value end 90th percentile. Category II : btw twice and 3 times the anomalie Category III : btw 3 times and four time the anomaly Category IV : observed value are higher than four times the anomaly btw mean and 90th percentile + the mean value.
