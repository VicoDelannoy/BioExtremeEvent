---
title: "BEE.calc.escape"
author: "Victoria"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---
BEE.calc.escape is not designed to work on 4D data (time + spatial 3D).

@description This function calculate the mediane distance, mean distance and standard deviation of distance to escape form an extreme event 'as the crow files' (but avoiding NA pixels) through time for a given GPS position or for all pixels.

@param data is Corrected_rasters, a binarized Spatraster (BEE.calc.true_event(binarized_EE, n = 5, d = 3)\[\["stacked_rasters_corrected"\]\]). (0 outside of event, 1 extreme event, NA land or missing data) OR Events_corrected, a list of df (obtained using BEE.calc.true_event(binarized_EE, n = 5, d = 3)\[\["Event_corrected"\]\] ) @param start_date and end_date defines the timeframe in during which you want to analyse distance to escape. If no dates are provided, computation will be done on all days_provided @param Set account_all_days = 'TRUE' if you want to perform calculations using all the days. Use account = 'FALSE' when you want to calculate only for the days when your reference point is experiencing an extreme event. By default, account_all_days is set on FALSE @param compute_by_event allows to specify if you want your result by extreme event or for the whole time periode specified. @param coords=NULL by defaults, values will be computed for all pixels of the raster, if your resolution is high and spatial exent is wide, this may be long. If you provide coordinate in decimal degrees (vector or df), values will only be computed for the given point.

@note all distance metrics are limited by the size of the Spatraster your are providing.

# Test en utilisant Events_corrected

```{r}
# true_event_output <- result ; start_date = "2022-08-01"; end_date = "2022-08-12" ; pixel = GPS ; only_days_EE = TRUE ; each_event = FALSE
BEE.calc.escape <- function(true_event_output, 
                start_date = NULL, end_date = NULL, 
                pixel, 
                only_days_EE = TRUE,
                each_event = TRUE) { 
# pixel is a vector with x,y coordinates or a df of x,y coordinates or "all" if you want to compute distance metrics for all pixels in the raster provided through true_event_output
# only_days_EE = FALSE : mean distance will be based on distances from all days in the time frame (belonging to an extreme event or not),  including all days belonging to this event event if they are a '0' day, TRUE : compute one mean distance accounting only for days that belong to an EE.
# "each_event" = TRUE : compute one mean distance per event,

### Recreate a Spatraster using Events_corrected. In this list, there are one df per pixel and one raw per dates
## Get data and shell
  data <- true_event_output[[2]]
  shell <- true_event_output[[1]]
## Select timeframe of interest to save computation time later
  # Check that dates from the two products of result match
  if (length(data[[1]]$Original_value) != nlyr(shell)) {
    warning("The two elements you provided as 'true_event_output don't cover the same number of days, please use the output of BEE.calc.true_event.")
  }
  date_indices <- match(c(start_date, end_date), names(shell))
  dates <- names(shell)[date_indices[1]:date_indices[2]]
  data <- lapply(data, \(df) df[date_indices[1]:date_indices[2], ])
  
  # Subset the layers in the timeframe of interest
  rasters <- subset(
  true_event_output$stacked_rasters_corrected,
  which(names(true_event_output$stacked_rasters_corrected) >= start_date &
        names(true_event_output$stacked_rasters_corrected) <= end_date)
)

  # coordinates of every pixel in the dataset :
  coords_all <- crds(rasters[[1]], df = TRUE, na.rm=FALSE, na.all = TRUE) 
      
  # Compute by data/layer
  dist_dir <- lapply(rasters, function(x) { # x <- rasters[[70]] # 1 : no MHX , 700 : 1 MHW # <-> iterate through dates
    values_x <- values(x)
    if (only_days_EE==TRUE){
    pixels_from <- which(values_x == 1)
    }
    if (only_days_EE==FALSE){
        pixels_from <- which(!is.na(values_x))
    }
    pixels_to <- which(values_x == 0)
    
    if (class(pixel)=="vector" | class(pixel)=="data.frame" ){
    pixels_to_do <- terra::cellFromXY(true_event_output$stacked_rasters_corrected,pixel)
    pixels_from <- pixels_from[which(pixels_from %in% pixels_to_do)]
    }
    
    # If there are some pixels to flee but no pixel where to escape :
   if (length(pixels_from) != 0 & length(pixels_to) == 0) { # the whole are is an EE
     coords_from <- coords_all[pixels_from, ]  # Coord to flee
      if (as.character(pixel)[1] == "all"){
      points <- data.table(
        date = time(x), 
        from_x = coords_from[,1],
        from_y = coords_from[,2],
        to_x = "unkown",
        to_y = "unkown",
        pixel_from_id =  as.integer(pixels_from),
        pixel_to_id = "no escape",
        distance = "outside of the raster",
        azimut = "not possible to compute"
      )
      }
      if (class(pixel)=="vector" | class(pixel)=="data.frame"){
      points <- data.table(
        date = rep(time(x), nrow(pixel)), 
        from_x = pixel[,1],
        from_y = pixel[,2],
        to_x = "unkown",
        to_y = "unkown",
        pixel_from_id =  as.integer(pixels_from),
        pixel_to_id = "no escape",
        distance = "outside of the raster",
        azimut = "not possible to compute"
      )
      }
   }
    if (length(pixels_from) == 0) { # nothing to escape from AND only_days_EE==TRUE (because when only_days_EE==FALSE, all pixel are considered as pixel to escape because we want to compute the distance to escape that are = 0.)
      if (as.character(pixel)[1] == "all"){
      points <- data.table(
        date = time(x), 
        from_x = NA,
        from_y = NA,
        to_x = NA,
        to_y = NA,
        pixel_from_id = NA,
        pixel_to_id = NA,
        distance = 0,
        azimut = NA
      )
      }
      if (class(pixel) =="vector" | class(pixel)=="data.frame"){
      points <- data.table(
        date = rep(time(x), nrow(pixel)), 
        from_x = pixel[,1],
        from_y = pixel[,2],
        to_x = NA,
        to_y = NA,
        pixel_from_id = pixels_to_do,
        pixel_to_id = NA,
        distance = rep(0,length(pixels_to_do)),
        azimut = NA
      )
      }
    }
    if (length(pixels_from) != 0 & length(pixels_to) != 0){ #Basic situation
    # Get coordinates of pixel to flee and pixel where to escape
    coords_from <- coords_all[pixels_from, ]  # Coord to flee
    coords_to <- coords_all[pixels_to, ]  # Coord refuge
    # Create a data.table
    points <- data.table(
      date = rep(time(x), nrow(coords_from)*nrow(coords_to)), 
      from_x = rep(coords_from[[1]], each = nrow(coords_to)),
      from_y = rep(coords_from[[2]], each = nrow(coords_to)),
      to_x = rep(coords_to[[1]], times = nrow(coords_from)),
      to_y = rep(coords_to[[2]], times = nrow(coords_from)),
      pixel_from_id = rep(pixels_from, each = nrow(coords_to)),
      pixel_to_id = rep(pixels_to, times = nrow(coords_from))
    )
    # Compute distances btw each points
    points[, distance := geosphere::distHaversine(cbind(from_x, from_y), cbind(to_x, to_y))]
    setorder(points, pixel_from_id, distance) # sort point by id (from_id) and then by shortest distance, when ex aequo, it keeps the same order as in 'points'
    points <- points[!duplicated(pixel_from_id), ] # keep only the first occurrence of each 'from_id' <-> the occurence with the shortest distance
    points[, azimut := (geosphere::bearing(cbind(from_x, from_y), cbind(to_x, to_y)) + 360) %% 360]
    }
    if (length(pixels_from) == 0 & length(pixels_to) == 0) {
      warning("There are no pixel of value 1 AND there are no pixel of value 0, the raster are probably not binarized (please see BEE.calc.binarized_EE and BEE.calc.true_event) or the raster is fully covered by NA.")
    }
    # Make sure that when they are no reason to leave a pixel (distance = 0), tha azimut is NA
    points[, azimut := ifelse(distance==0, NA, azimut)]
    return(points)
  })
  warnings("When several pixels are the 'closest pixel', the one with the smallest number/id is kept to compute shortest distance and azimut. Moreover, this function uses 'geosphere::distHaversine' to compute distances, it accounts for earth rotondity, which is better than euclidian distance, but it consider the earth as a sphere, thus near the poles, this methods is less percise than geosphere::distVincentyEllipsoid. This is a compromise between computation speed and precision. The estimate error using distHaversine compare to distVincentyEllipsoid is between 1 km and 5 km for a distance of 300 km.")
  dist_dir <- rbindlist(dist_dir)
  no_event <- dist_dir[which(pixel_to_id == "no escape"),] # saving the lines where there are no distances to compute for the case only_days_EE == FALSE
  if(only_days_EE==TRUE){
    dist_dir <- dist_dir[distance != 0,]
    if(nrow(dist_dir)==0){
      message("There were no extreme event for the given pixels and timeframe.")
    }
  }
  if (any(dist_dir$pixel_to_id=="no escape", na.rm = TRUE)){
    dangerous_date <- dist_dir$date[which(dist_dir$pixel_to_id=="no escape")]
    message("During the following dates, the raster was fully covered by an EE and it was no possible to compute a distance to escape or an azimut.", paste(dangerous_date, collapse = ", ") )
  }

  if (each_event==FALSE){ # dist_dir <- points
    return(dist_dir)
  }
  if (each_event==TRUE){
    # Here we want to give 'summary' type value compute across all day of a same event for each pixel (and event)
    # First, we need to re-identify all the days that belong to a same event :
    ## Create a data.table from  true_event_output[[2]] (data) with a column to easly identify the pixel represented in each row :
    data <- data[unique(dist_dir$pixel_from_id)] 
    names(data) <- unique(dist_dir$pixel_from_id)
    data <- rbindlist(data, idcol = "pixel_from_id")
    ## Recreate a column for the time interval of the event using the informaiton in the ID, this will be necessay to use foverlaps, the fastest function to identify if a date belongs to a specific timeframe or not :) :
    data[, c("start_date", "end_date") := tstrsplit(ID, "_", keep = 2:3)]
    data[, `:=`(start_date = as.Date(start_date), end_date = as.Date(end_date))]
    dist_dir[, `:=`(date_start = date, date_end = date)]
    ## Convert the pixel_id to the same format in both data.table :
    dist_dir[, pixel_from_id := as.integer(pixel_from_id)]
    data[, pixel_from_id := as.integer(pixel_from_id)]
    ## We need to delete 'event' that are bellow threshold (<-> distance == 0)
    
    ## Define the 'key' <-> the combination of colum used to create sub-group in a data.table format : 
    setkey(dist_dir, pixel_from_id, date_start, date_end) # PB
    setkey(data, pixel_from_id, start_date, end_date)
    
    dist_dir <- foverlaps( # magic function that found if the line from dt x is inside the time frame of a line from dt y and identify which one AND joint the 2 dt respecting correspondanies btw several column.
      dist_dir,
      data[, .(pixel_from_id, start_date, end_date, ID)],
      by.x = c("pixel_from_id", "date_start", "date_end"), # dt for which we need to know if it is inside the time frames of the other dt 
      by.y = c("pixel_from_id", "start_date", "end_date"), # the other dt, that contains all the reference timeframe
      nomatch = NA
    )
    ## Clean the columns date_start and date_end that are redondant with date
    dist_dir[, c("date_start", "date_end") := NULL]
    
    # Now we can compute some metrics of the metrics distance and azimut !!
    old_warn <- options("warn") # Save curent warning settings
    options(warn = -1) # unactivate warnings
    ## Distance
    dist_dir[,distance_mean := mean(as.numeric(distance), na.rm=T), by = ID]
    dist_dir[,distance_sd := sd(as.numeric(distance), na.rm=T), by = ID]
    dist_dir[,distance_median := median(as.numeric(distance), na.rm=T), by = ID]
    dist_dir[,distance_min := min(as.numeric(distance), na.rm=T), by = ID]
    dist_dir[,distance_max := max(as.numeric(distance), na.rm=T), by = ID]

    ## Since degree are a circular unit (after 360=0 comes 1,2...) we need a special way to compute it : 
    # Conversion to circular angle :
    dist_dir[, azimut_num := as.numeric(azimut)]
    dist_dir[, azimut_circ := ifelse(!is.na(azimut_num),
                                 circular::circular(azimut_num, units = "degrees", template = "geographics"),
                                 NA)]
    dist_dir[, azimut_mean := as.numeric(mean(azimut_circ, na.rm = TRUE)), by = ID]
    dist_dir[, azimut_med := median(azimut_circ, na.rm = TRUE), by = ID] # not possible to compute median on NA + if I just put NA, it is going to expect logical instead of numerical value, that's why NA-real and not NA
    dist_dir[, azimut_sd := {
      az_group <- azimut_circ[!is.na(azimut_circ)] #when there are to many decimals in azimut_circ, sin and cos used inside circular::sd induce littl imprecisions that leads to NA value when azimut_circ is constant, to deal with this, when azimut-circ is constant, a value of 0 is forced into the dt.
      if (length(az_group) <= 1 || max(az_group) - min(az_group) < 1e-6) {
        0
      } else {
        val <- suppressWarnings(as.numeric(sd(az_group)))
        if (is.nan(val)) 0 else val
      }
    }, by = ID]
    dist_dir[,azimut_min := min(azimut_num, na.rm = TRUE), by = ID]
    dist_dir[,azimut_max := max(azimut_num, na.rm = TRUE), by = ID]
        options(warn = old_warn$warn) # reactivate warnings
    # Delete column that refer to daily value and not to value compute on all the event :
    dist_dir[, c('date', 'distance', 'azimut', 'azimut_num','azimut_circ') := NULL]
    # Keep only one row per EE (<-> per value of ID column) :
    dist_dir <- dist_dir[, .SD[1], by = ID] #.SD keep the first line of every group of same value of ID   
    # delete the column x_to and y_to as the represent the pixel where to escape on first day and not a characteristic of the all event
    dist_dir <- dist_dir %>% select(-to_x, -to_y, -pixel_to_id)
    dist_dir <- dist_dir[!is.na(pixel_from_id)] # withrdraw the line of NA

    return(dist_dir)
  } 
  message("this combination of argument is not endle by the function")
}
```

  ###### ANCIENNE VERSION CI-DESSOUS

  if (account_all_days==TRUE){
    dist_final <- data.table()
  }
  if (account_all_days=="each_event" | account_all_days=="all_events" ){
    dist_final <- list()  
    position <- 0
  }
  
  for (i in pixels_to_do){
    # In true_event output[[2]] There is an alternation btw ID corresponding to an event above threshold (in absolut) and bellow threshold. To identify which ones belong to which category, we can calculate the % on 1 in odd ID position and in even ID position to see which ones are the event above threshold.
    dist_values <- terra::extract(distances, i)
    dir_values <- terra::extract(direction, i)
    #convert to data.table
    dist_values <- data.table(dates = colnames(dist_values),
                          daily_shortest_dist = t(dist_values)) %>%
      rename(daily_shortest_dist = daily_shortest_dist.V1)
    dir_values <- data.table(dates = colnames(dir_values),
                          daily_shortest_dir = t(dir_values)) %>%
      rename(daily_shortest_dir = daily_shortest_dir.V1)
    if (all(is.na(dist_values$daily_shortest_dist))){
      dist_values[,Event_ID := NA]
      dist_values[,Nb_days_no_escape := NA]
      dist_values[,Mean_dist := NA]
      dist_values[,Sd_dist := NA]
      dist_values[,Median_dist := NA]
      dist_values[,Min_dist := NA]
      dist_values[,Max_dist := NA]
      dist_values[,First_quart := NA]
      dist_values[,Third_quart := NA]
      dist_values[,Direction := NA]
      dist_values[,Mean_dir := NA]
      dist_values[,Sd_dir := NA]
      dist_values[,Median_dir := NA]
      dist_values[,Min_dir := NA]
      dist_values[,Max_dir := NA]
      dist_values[,First_quart_dir := NA]
      dist_values[,Third_quart_dir := NA]
        if (account_all_days==TRUE){
          dist_final <- rbind(dist_final, dist_values)
        }
        if (account_all_days=="each_event" | account_all_days=="all_events" ){
          position <- position+1
          dist_final[[position]] <- dist_values
        }
    }
    else{
      if (account_all_days == "each_event"){
      # Kepp only the lines corresponding to a true EE 
      odd <- seq(1, by = 2, length(unique(data[[i]]$ID)))
      even <- seq(2, by = 2, length(unique(data[[i]]$ID)))
      odd <- unique(data[[i]]$ID)[odd]
      even <- unique(data[[i]]$ID)[even]
      p_odd <- mean(data[[i]]$Cleanned_value[which(data[[i]]$ID %in% odd)])
      p_even <- mean(data[[i]]$Cleanned_value[which(data[[i]]$ID %in% even)])
      true_event_IDs <- list(odd, even)[[which.max(c(p_odd, p_even))]] #return the ID of the event above threshold
      # in data, row are in order (by date) and the first row represent start_date and the last_one represent end_date. We can use this to know 
      index <- as.numeric(which(data[[i]]$ID %in% true_event_IDs))
      # Then subset true_event_output[[2]] to keep only those dates
      dist_values <- dist_values[index] # NA when they are no escape in the are of the rasters
      # Then calculate distance to escape for those days
      dist_values[,Event_ID := data[[i]]$ID[which(data[[i]]$ID %in% true_event_IDs)]]
      # Resume by Event_ID
      dist_values <- dist_values[, .(
                        pixel = i,
                        date_start = min(dates),
                        date_end = max(dates),
                        Nb_days_no_escape = unique(length(daily_shortest_dist[ which( is.na(daily_shortest_dist))]), by = "Event_ID"),
                        Mean_dist = unique(mean(daily_shortest_dist, na.rm=TRUE), by = "Event_ID"),
                        Sd_dist = unique(sd(daily_shortest_dist, na.rm=TRUE), by = "Event_ID"),
                        Median_dist = unique(median(daily_shortest_dist, na.rm=TRUE), by = "Event_ID"),
                        Min_dist = unique(min(daily_shortest_dist, na.rm=TRUE), by = "Event_ID"),
                        Max_dist = unique(max(daily_shortest_dist, na.rm=TRUE), by = "Event_ID"),
                        First_quart = unique(quantile(x = daily_shortest_dist, na.rm=TRUE)[2], by = "Event_ID"),
                        Third_quart = unique(quantile(x = daily_shortest_dist, na.rm=TRUE)[3], by = "Event_ID")
                        ), by = Event_ID]
      # Calculate direction to escape for those days
      dir_values <- dir_values[index]
      dir_values[,Event_ID := data[[i]]$ID[which(data[[i]]$ID %in% true_event_IDs)]]
      # Resume by event
      dir_values <- dir_values[, .(
                        pixel = i,
                        date_start = min(dates),
                        date_end = max(dates),
                        Mean_dir = unique(mean(daily_shortest_dir, na.rm=TRUE), by = "Event_ID"),
                        Sd_dir = unique(sd(daily_shortest_dir, na.rm=TRUE), by = "Event_ID"),
                        Median_dir = unique(median(daily_shortest_dir, na.rm=TRUE), by = "Event_ID"),
                        Min_dir = unique(min(daily_shortest_dir, na.rm=TRUE), by = "Event_ID"),
                        Max_dir = unique(max(daily_shortest_dir, na.rm=TRUE), by = "Event_ID"),
                        First_quart_dir = unique(quantile(x = daily_shortest_dir, na.rm=TRUE)[2], by = "Event_ID"),
                        Third_quart_dir = unique(quantile(x = daily_shortest_dir, na.rm=TRUE)[3], by = "Event_ID")
                        ), by = Event_ID]
    escape_final <- cbind(dist_values,dir_values)
    position <- position+1
    dist_final[[position]] <- escape_final
    }
    if (account_all_days == TRUE){
      dist_values[,Event_ID := data[[i]]$ID]
      # Resume by Event_ID
      dist_values <- dist_values[, .(
                        pixel = i,
                        date_start = min(dates),
                        date_end = max(dates),
                        Nb_days_no_escape = unique(length(daily_shortest_dist[ which( is.na(daily_shortest_dist))]), by = "Event_ID"),
                        Mean_dist = unique(mean(daily_shortest_dist, na.rm=TRUE), by = "Event_ID"),
                        Sd_dist = unique(sd(daily_shortest_dist, na.rm=TRUE), by = "Event_ID"),
                        Median_dist = unique(median(daily_shortest_dist, na.rm=TRUE), by = "Event_ID"),
                        Min_dist = unique(min(daily_shortest_dist, na.rm=TRUE), by = "Event_ID"),
                        Max_dist = unique(max(daily_shortest_dist, na.rm=TRUE), by = "Event_ID"),
                        First_quart = unique(quantile(x = daily_shortest_dist, na.rm=TRUE)[2], by = "Event_ID"),
                        Third_quart = unique(quantile(x = daily_shortest_dist, na.rm=TRUE)[3], by = "Event_ID")
                        ), by = Event_ID]
      dist_final <- cbind(dist_values, dir_values)
    }
    if (account_all_days == "all_events"){
      # Kepp only the lines corresponding to a true EE 
      odd <- seq(1, by = 2, length(unique(data[[i]]$ID)))
      even <- seq(2, by = 2, length(unique(data[[i]]$ID)))
      odd <- unique(data[[i]]$ID)[odd]
      even <- unique(data[[i]]$ID)[even]
      p_odd <- mean(data[[i]]$Cleanned_value[which(data[[i]]$ID %in% odd)])
      p_even <- mean(data[[i]]$Cleanned_value[which(data[[i]]$ID %in% even)])
      true_event_IDs <- list(odd, even)[[which.max(c(p_odd, p_even))]] #return the ID of the event above threshold
      # in data, row are in order (by date) and the first row represent start_date and the last_one represent end_date. We can use this to know 
      index <- as.numeric(which(data[[i]]$ID %in% true_event_IDs))
      # Then subset true_event_output[[2]] to keep only those dates
      dist_values <- dist_values[index] # NA when they are no escape in the are of the rasters
      # Then calculate distance to escape for those days
      dist_values[,Event_ID := data[[i]]$ID[which(data[[i]]$ID %in% true_event_IDs)]]
      # Resume by Event_ID
      dist_values <- dist_values[, .(
                        Mean_dist = unique(mean(daily_shortest_dist, na.rm=TRUE), by = "Event_ID"),
                        Sd_dist = unique(sd(daily_shortest_dist, na.rm=TRUE), by = "Event_ID"),
                        Median_dist = unique(median(daily_shortest_dist, na.rm=TRUE), by = "Event_ID"),
                        Min_dist = unique(min(daily_shortest_dist, na.rm=TRUE), by = "Event_ID"),
                        Max_dist = unique(max(daily_shortest_dist, na.rm=TRUE), by = "Event_ID"),
                        First_quart = unique(quantile(x = daily_shortest_dist, na.rm=TRUE)[2], by = "Event_ID"),
                        Third_quart = unique(quantile(x = daily_shortest_dist, na.rm=TRUE)[3], by = "Event_ID")
                        ), by = Event_ID]
      position <- position+1
      dist_final[[position]] <- dist_values
      }
    }
  }
  return(dist_final)