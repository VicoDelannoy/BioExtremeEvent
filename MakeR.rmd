---
title: "MakeR"
author: "Victoria"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---

```{r}
# 
#   ____   _          ______        _                                 ______                   _   
#  |  _ \ (_)        |  ____|      | |                               |  ____|                 | |  
#  | |_) | _   ___   | |__   __  __| |_  _ __  ___  _ __ ___    ___  | |__ __   __ ___  _ __  | |_ 
#  |  _ < | | / _ \  |  __|  \ \/ /| __|| '__|/ _ \| '_ ` _ \  / _ \ |  __|\ \ / // _ \| '_ \ | __|
#  | |_) || || (_) | | |____  >  < | |_ | |  |  __/| | | | | ||  __/ | |____\ V /|  __/| | | || |_ 
#  |____/ |_| \___/  |______|/_/\_\ \__||_|   \___||_| |_| |_| \___| |______|\_/  \___||_| |_| \__|
#                                                                                                  
#                                                                                                  
```

This file is the main skeleton of the package BioExtremEvent (BEE) and guide you through the different steps of analysis. Most of the functions use 'mclapply', which is only able to parallelize calculations on macOS and Linux. If you're running the code on Windows, computation time may be longer.

# 1. Load dependencies and associated functions

```{r}
#'@description
## R Parameters ----
rm(list=ls())
set.seed(666) #to get the same randomization across users

## Install Dependencies (listed in DESCRIPTION) ----
remotes::install_deps(dependencies = TRUE, upgrade = "never", force = TRUE) #list of all the packages required for this package to run)

## Load Project Addins (R Functions and Packages) ----
pkgload::load_all(here::here()) #here::here find files were the skeleton file is located



## Load .qmd file (functions)
files.source <- list.files(path = here::here(), pattern = "\\.qmd$", full.names = TRUE, recursive = TRUE)

# Withdraw Make.R file from the list to avoid infinit loop
files.source <- files.source[!grepl("MakeR.qmd", files.source)]

sapply(files.source, function(file) {
  rmarkdown::render(file, envir = .GlobalEnv)  #Excute code and load functions
})
```

# 2. Get your data ready

Detecting an 'extreme' event implies to know what are the normal conditions, thus, it is recommended to provide a 30 years times series. This can be painful to download manually from Copernicus Marine Data center or NOAA website as they often limit the amount of rasters that can be download. Therefore, here bellow are two functions to download data from R. They allows data to be dowloaded much faster ;) - BEE.data.Load_Copernicus is a wrapper from the python function "CopernicusMarine". - BEE.data.Load_NOAA is wrapper of some code coming from the heatwaveR package. - You can also download your raster manually on any website, make sure to use a NetCDF format and to stack your rasters without gaps in the time serie.

## From Copernicus

```{r}
# username <- "vdela"
# password <- "Marbec_2WAVE"
ds <- BEE.data.Load_Copernicus(username=username, password=password,
                               dataset_id="cmems_SST_MED_SST_L4_REP_OBSERVATIONS_010_021",
  dataset_version="202411",
  variables= list("analysed_sst"),
  minimum_longitude=2.9,
  maximum_longitude=7.8,
  minimum_latitude=42,
  maximum_latitude=43.7,
  start_datetime="1983-01-01T00:00:00",
  end_datetime="2024-12-30T00:00:00",
  coordinates_selection_method="strict-inside",
  disable_progress_bar=FALSE,
  output_directory = here::here("Data"))
```

## From NOAA

HERE I MUST ADD A WRAPPED VERSION OF HEATWAVE3

## Get your dataset in the environnement

You can start from here is your data are already in your computer.

```{r}
ds <- rast("Data/cmems_SST_MED_SST_L4_REP_OBSERVATIONS_010_021_analysed_sst_2.94E-7.80E_42.01N-43.67N_1983-01-01-2024-12-30.nc")
# Each layer name must be the corresponding date under YYYY-MM-DD format
time(ds) <- as.Date(gsub(" UTC", "", time(ds)))
names(ds) <- time(ds)
```

## Convert to Celsius

If your using the package to work on temperature raster, you can check that the unit is Celsius (and make conversion if necessary) using the function bellow.

```{r}
ds <- BEE.calc.celsius(ds)
```

# 3. Calculate a baseline value for each cell in your dataset using one of two methods with "*EE.calc.baseline"* :

-   [Dynamic Baseline]{.underline} (Seasonal Threshold): Compute the a percentile of daily mean values for each cell and each day of a "theoretical year" across the entire time series. Percentile must be beetwen 0 and 1. Example: For daily data from 1981–2020, this creates 365 threshold values per grid cell, one for each day of the year. Use case: Broad studies (e.g., comparing community responses or regions). Note : if you want to study data bellow the seasonal mean you must calculate a baseline for the first quantile (in case distribution is not symmetric around the mean). Example : value = 0.1 to study the 10 percent lowest value.

-   [Mean Baseline]{.underline} : Use a mean value or a constant temperature value based on biological or ecological relevance (see later part XX). Example: A mortality threshold that does not vary by season or location. Use case: Specific models or questions focused on fixed biological limits.

-   [Fixed Threshold]{.underline} (Biological Threshold): you can set an absolute value as a threshold directly in EE.calc.binarized.

-   start_date and end_date are NULL if no date provided. Warning, dates but be under "YYYY-MM-DD" format.

```{r}
# Dynamic Baseline ; 1 minutes 40 s to run on 3 332 pixels and 10 227 days
baseline_qt90 <- BEE.calc.baseline(rast_name = ds, end_date = "2010-12-31", threshold = "qt", quantile_value = 0.9) 
saveRDS(baseline_qt90, here::here("Outputs", "baseline_qt90.rds"))
baseline_qt90 <- readRDS(here::here("Outputs", "baseline_qt90.rds"))
# Mean Basline 
baseline_mean <- BEE.calc.baseline(rast_name = ds, end_date = "2010-12-31", threshold = "mean", quantile_value = NULL)
saveRDS(baseline_mean, here::here("Outputs", "baseline_mean.rds"))
baseline_mean <- readRDS(here::here("Outputs", "baseline_mean.rds"))
```

# 4. Binarize spatial data : This step test for each cell of the area whether the metric of the 'event' is above or 'bellow' the threshold.

It provide a raw information for each day and each pixel without applying any definition of the Extreme Event. Of course, one may be interesting in applying a more restrictive definition of "Extreme Event". This will be done when BEE.calc.true_event will be used (later). This intermediate step is necessary to apply BEE.calc.true_event.

The 29 of February is removed.

```{r chunk-5}
binarized_EE <- BEE.calc.binarize(rast_name= ds, baseline=baseline_qt90, direction = "above") #by default, direction == "above"

# plot(baseline_qt90[[1]]) ; plot(binarized_EE$`01.01`$`1983-01-01`)
```

You can use the output to check which are the pixel more subject to peaks of your studdied parameter :

```{r}
# # exemple : sst on the 23th of august
# plot(sum(binarize_EE$`08.23`))
# # exemple : sst on the 23th of august in %
# plot(sum(binarize_EE$`08.23`)*100/terra::nlyr(binarize_EE$`08.23`),
#      main = "Percentage of years above threshold on the 23th of August between 1983 and 2024")
# #More recently
# layer_dates <- as.Date(names(example))
#     selected_layers <- which(layer_dates >= "2011-01-01" & layer_dates <= "2024-12-31")
#     example_2010_2024 <- example[[selected_layers]]
# plot(sum(example_2010_2024)*100/terra::nlyr(example_2010_2024),
#      main = "Percentage of years above threshold on the 23th of August between 2010 and 2024")
# # % of MHW have roughly doubled
```

# 5. Identify Extreme Event

Delete short period above threshold from the list of extreme event and merge close periods above threshold. Provide informations on the amount of modifications.

```{r}
# 5 minutes 56 s to run on 3 332 pixels and 10 227 days
gc()
# For Windows :
result <- BEE.calc.true_event(binarized_EE, n = 5, d = 3)
Corrected_rasters <- result$stacked_rasters_corrected
Events_corrected <- result$Event_corrected
saveRDS(Events_corrected, file = here::here("Outputs", "Events_corrected.rds"))
test_Events_corrected <- readRDS(here::here("Outputs/Events_corrected.rds"))
gc()
#testL <- as.Date.character(c("2022-11-25", "2022-11-26", "2022-11-27", "2022-11-28", "2022-11-29", "2022-11-30", "2022-12-01", "2022-12-02", "2022-12-03", "2022-12-04", "2022-12-05")) ; test <- Corrected_rasters[[names(Corrected_rasters) %in% as.character(testL)]] ;library(viridis) ; plot(sum(test),  col = viridis::viridis(4))  ; plot(Corrected_rasters["2022-11-30"])
# saveRDS(result, file= here::here("Outputs/result.rds")) ; test_result <- readRDS(here::here("Outputs/result.rds"))
#Check settings
BEE.calc.corrections(Events_corrected)
```

# 6. Get metrics related to time using detect_event() from heatwaveR package.

The function bellow gives you basic metrics for a given GPS position, list of position, polygones or list of polygones.

```{r}
GPS <- data.frame(x = c(3.766, 5.386, 3.146), # Frontignan, îles du Frioul, Banyuls
                  y = c(43.428, 43.183, 42.781))
metrics <- BEE.calc.metrics_points()
```

For instance, if you are intrested in marine heat wave you may want to apply Hobday et al. 2016 definition and only keeps the days above treshold when they belongs to a series of 5 days (or more) above threshold and you may want to group these event under a same event when they are distant from 3 days or less. For biological reasons mainly, you may want to apply a more specific definition of 'biologically extreme event'. To see options please look at : ???????????

# ICI COMMENCE UN BROUILLON A REUTILISER POUR CALCULER LES METRICS

The heatwaveR package has a very efficient couple of function to calculate baseline and identify extreme event according the definition of Hobday et al. 2016. The first function requires a df and not a spat raster thus, we wrapped conversion from SpatRAster to df and the 2 functions from heatwaveR under a unique function BEE.calc.baseline and BEE.calc.event UTILISER LES FONCTIONS DE HEATWAVER mais en faisant la parallélisation sur tous les pixels soit mêmes : Faire une liste de df (1 par pixel) puis appliquer ts2clm et detectevent en parallèle sur les différents éléments de la liste

Si c'est trop complexe de relocaliser les pixels il faudra enlever le filtrage des pixels avec que des NA.

```{r chunk-6}

# Charger les packages nécessaires
library(terra)
library(heatwaveR)
library(purrr)
library(dplyr)
library(tictoc)

# Supposons que 'ds' est votre SpatRaster
# ds <- rast("chemin/vers/votre/fichier.tif")
tic()

# Extraire les dates des noms des couches
dates <- names(ds) %>% as.Date(format = "%Y-%m-%d")

# Fonction pour traiter un pixel
process_pixel <- function(pixel_values) {
  # Ignorer les pixels non valides (tous NA)
  if (all(is.na(pixel_values))) return(NULL)
  
  # Créer un dataframe avec les dates et les valeurs de température
  df <- data.frame(t = dates, temp = pixel_values)
  
  # Appliquer ts2clm
  clim <- ts2clm(df, climatologyPeriod = c(min(dates), max(dates)))
  
  # Détecter les événements de chaleur
  detect_event(clim)
}

# Extraire les valeurs du raster sous forme de matrice
pixel_matrix <- terra::values(ds)

# Filtrer les pixels non valides (tous NA)
valid_pixels <- apply(pixel_matrix, 1, function(x) !all(is.na(x)))
pixel_matrix <- pixel_matrix[valid_pixels, ]

# Activer le parallélisme
plan(multisession, workers = parallel::detectCores() - 1)
print(paste("Nombre de cœurs utilisés :", nbrOfWorkers()))
# Appliquer la fonction en parallèle
results <- future_map(asplit(pixel_matrix, 1), process_pixel, .progress = TRUE)

toc()

# results contient maintenant les résultats pour chaque pixel
# Extraire les résultats et les erreurs
results_list <- transpose(results)
successful_results <- results_list$result
```
